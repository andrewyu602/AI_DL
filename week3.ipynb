{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8w0Ct9LQPxqCyi4UGjsnd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewyu602/AI_DL/blob/main/week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions 1."
      ],
      "metadata": {
        "id": "rJ-qCgaTRftY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rICV6psaPSJs"
      },
      "outputs": [],
      "source": [
        "def naive_relu(x):\n",
        "    assert len(x.shape) == 2\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] = max(x[i, j], 0)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_add(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert x.shape == y.shape\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[i, j]\n",
        "    return x"
      ],
      "metadata": {
        "id": "rKT2jo8FR4b8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "ab = np.ones((2,2))\n",
        "ab[0,0] = 5\n",
        "ab[1,1] = -1\n",
        "ab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNKf1GJPPzQh",
        "outputId": "d9542d74-2eae-4656-ecd4-b4c5844748cd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.,  1.],\n",
              "       [ 1., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_relu(ab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2AEiP4vTZbG",
        "outputId": "20b3c82b-a79c-43b9-f8fb-1ffdabaa4d37"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5., 1.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bb = np.ones((2,2))\n",
        "bb[1,1] = 0\n",
        "bb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_4OQRDYQhUZ",
        "outputId": "187377c7-e447-4a1f-d5c6-21cddc5f794f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ab + bb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3_43OpaQn0m",
        "outputId": "b788ad86-ece7-4531-8b1f-00148c7ede9b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.,  2.],\n",
              "       [ 2., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = naive_add(ab, bb)"
      ],
      "metadata": {
        "id": "7UplBm8fQokM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_relu(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtN9a6u9SUJW",
        "outputId": "f825bd1d-232e-4da6-932e-34b43ce5cb51"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6., 2.],\n",
              "       [2., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "x = np.random.random((20, 100))\n",
        "y = np.random.random((20, 100))\n",
        "\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = x + y\n",
        "    z = np.maximum(z, 0.)\n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CroNiv6ShOi",
        "outputId": "952f65d8-fcff-4d7d-b5dc-640ada781f2e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took: 0.01 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = naive_add(x, y)\n",
        "    z = naive_relu(z)\n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z1WfiPvSjMT",
        "outputId": "e41476a5-e5ed-4fc0-9c74-22474e832446"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took: 2.52 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions 2\n",
        "\n",
        ": it is because without using .copy, the actual data, which is used as the input of the function, is changed.\n",
        "\n",
        ": To prevent the actual data"
      ],
      "metadata": {
        "id": "2Tu8zNYKRltx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions 3\n",
        "\n",
        ": naive version of the code is slower because it utilizes the loop while np.maximum calculates through vectorization."
      ],
      "metadata": {
        "id": "EO_f6ajXTs8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions 4"
      ],
      "metadata": {
        "id": "JqJ2YK8TUmD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.random.random((50, 15))\n",
        "Y = np.random.random((15,))"
      ],
      "metadata": {
        "id": "XfQfC_DqRoTb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqXU_zjVUoNW",
        "outputId": "ea55118d-d55b-48ea-c847-de8bf26aacb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBj1mIFzUp4N",
        "outputId": "2520f0a8-f96a-4734-c8a0-100545d05ed4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X + Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvopKo-lUqxI",
        "outputId": "65fde9bd-0502-41b0-ded4-d77fc428aafc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.00333364, 0.306809  , 0.91210568, 1.21940765, 1.40880115,\n",
              "        0.50976583, 0.86035923, 1.42758226, 0.40781609, 0.66401428,\n",
              "        0.75993635, 1.18966034, 1.02639973, 0.63585744, 0.5887434 ],\n",
              "       [1.82733095, 0.62278395, 1.05631693, 1.63831461, 1.25059945,\n",
              "        0.6429447 , 1.12889719, 0.94629717, 1.09931308, 1.39598868,\n",
              "        1.17620602, 1.11873718, 1.30909785, 0.5511654 , 1.13758288],\n",
              "       [1.09222512, 0.21469752, 0.92752428, 1.34052779, 0.89196638,\n",
              "        0.62701407, 0.71602946, 0.72731519, 0.41936532, 0.90452149,\n",
              "        1.09237347, 1.34959358, 1.45683218, 0.55886198, 0.41615486],\n",
              "       [1.80419438, 0.76226303, 1.07582708, 1.60977652, 0.64744133,\n",
              "        0.67093204, 1.4688801 , 0.77873177, 1.1240458 , 1.37485809,\n",
              "        1.24864751, 1.31488017, 1.23984369, 0.86304908, 0.74337831],\n",
              "       [1.39949681, 0.5318981 , 0.5969613 , 1.22624342, 0.49767315,\n",
              "        0.20964069, 1.4846331 , 0.84958301, 0.49219264, 0.93637881,\n",
              "        0.82152646, 0.98148076, 0.60260001, 0.15035595, 0.68119737],\n",
              "       [1.29059169, 0.17739731, 1.03449577, 1.16650642, 1.21610254,\n",
              "        0.51545265, 0.80113631, 0.92160128, 0.84688312, 1.04625102,\n",
              "        0.62666008, 1.5043791 , 1.20692507, 0.82439971, 0.5107853 ],\n",
              "       [0.96959365, 0.93844359, 0.87219188, 1.00097517, 1.23961513,\n",
              "        1.0023655 , 0.84949132, 1.52045789, 0.66945064, 0.97814697,\n",
              "        1.0264335 , 1.35145504, 1.45573397, 0.32251209, 0.53556528],\n",
              "       [1.71500569, 0.99556835, 1.26223065, 0.89771105, 0.50055835,\n",
              "        0.33440174, 1.2519041 , 0.74977525, 0.60643283, 0.86193448,\n",
              "        1.28417593, 0.79892938, 0.91419568, 0.21337666, 0.89898587],\n",
              "       [1.52617332, 0.77090437, 0.65994134, 1.1789255 , 0.82553764,\n",
              "        0.19635075, 1.56035016, 1.2134398 , 1.03300692, 0.93635529,\n",
              "        0.5911806 , 1.46263849, 0.67298048, 0.4769073 , 0.85854849],\n",
              "       [1.51739199, 0.56216866, 1.38372807, 1.45296593, 1.20317583,\n",
              "        0.88105314, 1.05592235, 0.85053432, 0.75715442, 1.29423963,\n",
              "        0.53245104, 1.39368448, 1.28120694, 0.64672119, 1.24627782],\n",
              "       [1.81777925, 0.6265673 , 1.42302633, 1.54396014, 0.48803811,\n",
              "        0.04414497, 1.20250953, 0.69978029, 1.04910534, 0.46936957,\n",
              "        0.92654518, 1.58232262, 1.13377366, 0.28004654, 0.55229107],\n",
              "       [1.72042065, 0.62712567, 0.65468062, 1.18037706, 1.10396278,\n",
              "        0.5068251 , 1.56766552, 0.66986962, 0.38451151, 0.53146599,\n",
              "        1.40403258, 1.19960995, 0.64028166, 0.34233423, 0.92115855],\n",
              "       [1.48073027, 0.0806538 , 1.3590155 , 1.11855257, 1.30222312,\n",
              "        0.41651775, 1.32693427, 0.77710491, 0.46463719, 1.18552455,\n",
              "        0.64320998, 1.3936332 , 0.56609717, 1.02824863, 0.43324676],\n",
              "       [0.97384006, 0.32929111, 0.81791274, 1.29525131, 1.27346868,\n",
              "        0.43429011, 1.67644793, 1.18127823, 0.76877233, 1.39294473,\n",
              "        1.33436803, 1.20483678, 0.55643927, 1.07945001, 1.24089894],\n",
              "       [1.82100092, 0.0035919 , 0.67265604, 1.47419174, 0.88806711,\n",
              "        0.67606546, 1.26528144, 0.72487757, 0.54654335, 1.38934435,\n",
              "        0.91006918, 1.53309895, 1.3474197 , 0.32007588, 1.15524146],\n",
              "       [1.65406086, 0.27194373, 0.58604112, 1.08663595, 1.00871273,\n",
              "        0.06383161, 0.94953804, 0.63551609, 0.56582502, 1.0821191 ,\n",
              "        1.42307981, 0.68758659, 0.96199605, 0.99662523, 1.25161158],\n",
              "       [1.75893269, 0.88661037, 0.79307164, 0.89173554, 1.21737365,\n",
              "        0.71841075, 0.87533377, 0.9326155 , 0.96314489, 0.60470046,\n",
              "        0.9373152 , 0.92106294, 0.62613416, 0.23058072, 0.55422769],\n",
              "       [1.46390958, 0.73465961, 1.25078666, 1.14359668, 1.20648462,\n",
              "        0.17579858, 1.2604501 , 0.93910147, 0.71913651, 0.43230185,\n",
              "        0.56973005, 1.12369503, 0.48266703, 0.6790772 , 0.64736649],\n",
              "       [1.3436875 , 0.93220512, 0.73786202, 1.15190223, 1.39242402,\n",
              "        0.92651058, 0.78236566, 1.34906683, 0.36143493, 0.84002679,\n",
              "        1.19824305, 0.8054566 , 1.09630412, 0.70625055, 1.10268299],\n",
              "       [1.31331615, 0.34348442, 0.53900182, 0.94986588, 0.93304125,\n",
              "        0.27936456, 1.64693032, 0.70520239, 0.68571209, 1.17343704,\n",
              "        1.26688133, 1.54401737, 0.68704534, 0.17485388, 1.20623567],\n",
              "       [1.48990592, 0.53365019, 1.39867077, 1.13388934, 0.89645429,\n",
              "        0.18173682, 0.97411908, 1.07706543, 0.74550293, 0.72702705,\n",
              "        1.04942496, 1.09833605, 1.11514191, 0.15493841, 0.50092   ],\n",
              "       [1.72483975, 0.43637968, 0.98997219, 1.18294277, 1.12613523,\n",
              "        0.45697598, 1.26606266, 1.19508119, 0.27064607, 1.14336245,\n",
              "        0.63487053, 0.86620118, 0.62281516, 0.29220056, 1.03602496],\n",
              "       [1.56073914, 0.78196842, 1.18014535, 1.19493927, 1.09830111,\n",
              "        0.48783529, 0.92027701, 1.44154177, 0.5518466 , 1.05034546,\n",
              "        0.66224855, 1.54640997, 1.36415832, 0.58106862, 1.23488817],\n",
              "       [0.94840769, 0.14053654, 1.39947661, 1.85732272, 1.15816916,\n",
              "        0.71226488, 0.73419615, 1.42194547, 0.93083155, 0.7934505 ,\n",
              "        1.01517878, 1.55928883, 1.08001687, 0.12741794, 1.37723611],\n",
              "       [0.99412768, 0.5073828 , 0.6085514 , 1.86813477, 1.39742301,\n",
              "        0.20483775, 0.73997498, 1.22954271, 1.06722115, 1.22030656,\n",
              "        1.37127667, 0.75888871, 1.22810618, 0.39368459, 0.69233857],\n",
              "       [1.1650062 , 0.91021906, 0.6655536 , 0.93087574, 0.74595798,\n",
              "        0.70109756, 0.85362984, 1.45285318, 0.55254849, 1.11696748,\n",
              "        0.8927112 , 0.68936062, 1.37726653, 0.73382601, 0.49278222],\n",
              "       [1.82025909, 0.85637147, 1.1246634 , 1.40002736, 0.49723427,\n",
              "        0.90056291, 1.67941409, 1.41749025, 0.57883173, 1.05770324,\n",
              "        1.00440661, 0.93448571, 0.54550776, 0.95472706, 0.62190301],\n",
              "       [1.0645376 , 0.53577912, 0.75362466, 1.56005334, 1.15038672,\n",
              "        0.75212278, 1.03429825, 0.95560305, 0.83893806, 0.89068697,\n",
              "        1.18420849, 1.03939068, 1.44142106, 0.16307801, 0.8615665 ],\n",
              "       [1.62206305, 0.57067847, 1.44672712, 1.43447323, 0.72445062,\n",
              "        0.34917522, 1.24473417, 1.09944409, 0.38941216, 1.28911031,\n",
              "        0.66442278, 1.05884591, 1.20986423, 0.39191265, 1.03488685],\n",
              "       [1.91043704, 0.90263335, 1.15620634, 1.81826259, 0.46394529,\n",
              "        0.75378289, 0.80074629, 1.21880262, 0.24874388, 1.21965953,\n",
              "        0.62371194, 1.38204455, 1.18086197, 0.16413274, 0.81684342],\n",
              "       [1.90746911, 0.32320105, 0.66877688, 1.56560367, 0.71349202,\n",
              "        0.50409469, 1.08270012, 0.63851809, 0.26026157, 1.32625225,\n",
              "        0.95667893, 0.81106236, 0.98019914, 0.87632001, 0.97380896],\n",
              "       [1.28929367, 0.43890489, 0.52995467, 0.92851226, 1.26346346,\n",
              "        0.42721193, 1.35254829, 1.09129613, 1.02067821, 0.83029966,\n",
              "        1.05378976, 1.21793977, 0.59369116, 0.54881293, 1.37783898],\n",
              "       [0.94898625, 0.72672581, 0.87789428, 1.48152519, 0.70037054,\n",
              "        0.68460971, 0.93978206, 1.2378737 , 0.32161628, 0.63554935,\n",
              "        1.36855063, 1.33416089, 1.33688744, 0.67508994, 0.65531054],\n",
              "       [1.33089412, 0.67194074, 1.42588045, 1.86223718, 0.9231537 ,\n",
              "        0.35140328, 1.53165996, 0.88605713, 0.43771424, 1.27615672,\n",
              "        1.2343292 , 0.75375166, 1.41613153, 0.48895616, 1.40535731],\n",
              "       [1.03094262, 0.85062307, 0.90964811, 1.15514352, 0.60983255,\n",
              "        0.18956026, 0.74467609, 0.61489452, 0.84531016, 1.32344539,\n",
              "        0.4507594 , 1.04936081, 0.96306491, 0.38745095, 0.73670732],\n",
              "       [1.74259835, 0.16192935, 0.75788048, 1.71189204, 1.14300832,\n",
              "        0.52043886, 1.63076587, 0.62665971, 0.24766995, 0.53840132,\n",
              "        0.76107047, 0.67055082, 0.79871645, 0.70640288, 0.41303778],\n",
              "       [1.66408854, 0.72894801, 0.75196394, 1.62456361, 0.92472659,\n",
              "        0.21243457, 1.67787752, 1.37499996, 0.50833486, 1.36390222,\n",
              "        1.01218299, 1.5689781 , 0.59211738, 0.85323171, 1.36234798],\n",
              "       [1.67373714, 0.14933239, 0.74789233, 1.87734614, 0.77990649,\n",
              "        1.00505076, 1.27316351, 0.5940041 , 1.14847695, 0.64610607,\n",
              "        1.21527037, 0.92846529, 1.18911578, 0.69297358, 1.23633018],\n",
              "       [1.13587748, 0.8834364 , 0.56400355, 1.86245819, 1.18381524,\n",
              "        0.16420606, 0.99883284, 0.63421911, 0.87680603, 0.64857718,\n",
              "        1.22240275, 1.40179288, 1.07462272, 0.70384984, 1.03047691],\n",
              "       [1.81263945, 0.66555564, 0.59187804, 1.71150068, 1.1701693 ,\n",
              "        0.75441901, 1.33984243, 0.84462392, 0.68215817, 1.05049034,\n",
              "        0.4901819 , 1.04007349, 1.36534677, 0.80200957, 0.75729476],\n",
              "       [1.54922479, 0.65541252, 0.96210021, 0.98278378, 0.99031657,\n",
              "        0.30162029, 1.37535327, 1.00282813, 0.54996359, 1.24368427,\n",
              "        0.92480584, 1.14688235, 1.10245089, 0.16300878, 1.36986859],\n",
              "       [1.71749547, 0.82976492, 1.33283655, 0.9489216 , 1.31656407,\n",
              "        0.67867972, 0.8168567 , 0.89760657, 0.50232998, 0.66660065,\n",
              "        0.75975846, 1.39620577, 0.91846057, 0.82356762, 0.45860055],\n",
              "       [1.55579083, 0.50119106, 0.58234321, 1.16372184, 0.97702665,\n",
              "        0.86515657, 0.7705908 , 1.4472735 , 0.96109251, 0.73792241,\n",
              "        1.351795  , 1.60764379, 1.2199111 , 0.58974626, 1.18272069],\n",
              "       [1.65798279, 0.699952  , 1.33876592, 1.68311013, 1.27096044,\n",
              "        0.83617756, 1.39259106, 1.05290373, 0.74514894, 0.68731701,\n",
              "        1.35080766, 1.02229329, 0.99068125, 0.94627594, 0.43488627],\n",
              "       [1.74647053, 0.49516702, 0.61983172, 1.7010041 , 0.93325941,\n",
              "        0.41647052, 1.18867088, 0.86959456, 0.63771465, 1.13036799,\n",
              "        0.75954995, 1.60565197, 1.27025285, 1.09055549, 0.93054496],\n",
              "       [1.63165746, 0.83911148, 1.45750658, 1.27955306, 0.53858614,\n",
              "        0.68977384, 1.43859674, 0.83648662, 0.26125477, 1.18733685,\n",
              "        0.87998842, 1.38301186, 1.14623234, 0.39008859, 1.29679954],\n",
              "       [1.55030212, 0.88144216, 1.20381745, 1.69112329, 1.14019694,\n",
              "        0.02330473, 1.44252687, 0.70050312, 0.30788708, 0.52677617,\n",
              "        1.28810454, 1.38024798, 1.11259845, 0.18145285, 1.05722168],\n",
              "       [1.6798082 , 0.81773367, 1.37414311, 1.44165103, 1.0170842 ,\n",
              "        0.53738083, 1.63892426, 0.62891867, 1.14265167, 0.82398658,\n",
              "        1.30267766, 0.88699793, 0.6432596 , 0.8634737 , 0.45461959],\n",
              "       [1.52355774, 0.84961231, 0.92291725, 1.83951674, 0.45884899,\n",
              "        0.42548954, 1.19565171, 1.55071089, 0.46129657, 0.8448528 ,\n",
              "        1.36795904, 1.00288291, 0.54117928, 0.32855319, 0.94662804],\n",
              "       [1.31133353, 0.43724145, 1.19775353, 1.01390233, 0.62075824,\n",
              "        0.90591414, 1.59521578, 1.16530766, 0.37211753, 1.05113498,\n",
              "        1.34878942, 1.5036889 , 0.55049079, 0.3187327 , 1.07497282]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = np.expand_dims(y, axis=0) # 행 벡터로 확장한 것"
      ],
      "metadata": {
        "id": "E9xfKiXwUr8T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ge1HmK_Uvsg",
        "outputId": "2086a6f9-756c-46cb-f3d3-94f36df70896"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.41832023, 0.04803445, 0.46214868, 0.77334167, 0.00499024,\n",
              "        0.42034524, 0.41091893, 0.81557034, 0.52592394, 0.34832171,\n",
              "        0.42466763, 0.93543085, 0.86291004, 0.35111638, 0.47769095]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions 5"
      ],
      "metadata": {
        "id": "rlcpjTkMWXXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[0., 1.],\n",
        "             [2., 3.],\n",
        "             [4., 5.]])\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbq623QsWUu5",
        "outputId": "ab030cef-726a-42de-84d3-400af68e3cb1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.reshape((1, 6))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5BOI15GPxjF",
        "outputId": "15634ad1-d5c5-40f3-9686-b4a55ea2b745"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 2., 3., 4., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.ones((5,2))\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmGQB5ApQBZK",
        "outputId": "8b9265d2-6237-4302-d49b-06c122dc13f0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = np.transpose(a)\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX6EBZ3tQovp",
        "outputId": "d62051dc-32ff-40fb-c985-44f10000fa53"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_2JGVa5QuOc",
        "outputId": "b3680e10-db1d-48ac-e757-c335bbee0ba9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions 6"
      ],
      "metadata": {
        "id": "s7ZH_dHjWY__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "x = tf.Variable(0.)\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 2 * x + 3\n",
        "grad_of_y_wrt_x = tape.gradient(y, x)"
      ],
      "metadata": {
        "id": "FRolPg99Wazn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_of_y_wrt_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj9ICcq-WeBl",
        "outputId": "bf35bb18-0315-4187-c4f8-cf08b23a34d2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(tf.random.uniform((2, 2)))\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 2 * x + 3\n",
        "grad_of_y_wrt_x = tape.gradient(y, x)"
      ],
      "metadata": {
        "id": "LXqw7UQcWi1W"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_of_y_wrt_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytCXg_JNWn2P",
        "outputId": "b5eddad5-1895-4c4f-cb14-eb9d9ddc9f17"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[2., 2.],\n",
              "       [2., 2.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = tf.Variable(tf.random.uniform((2, 2)))\n",
        "b = tf.Variable(tf.zeros((2,)))\n",
        "x = tf.random.uniform((2, 2))\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.matmul(x, W) + b\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])"
      ],
      "metadata": {
        "id": "U0KJieOnWonv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_of_y_wrt_W_and_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mRYzRTMWxN7",
        "outputId": "f3a07e12-2086-4927-f5bf-45ee87ae0fe6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              " array([[0.23023415, 0.23023415],\n",
              "        [0.6326771 , 0.6326771 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x = tf.Variable(2.0)\n",
        "y = tf.Variable(1.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    f = x**2 * y + x * y + 3 * y\n",
        "grad_of_f_wrt_x_and_y = tape.gradient(f, [x,y])"
      ],
      "metadata": {
        "id": "EJO5hb7IWzQg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_of_f_wrt_x_and_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkJQM98JbScS",
        "outputId": "c2334b27-7bf8-4ea4-a3a1-187fa5fc2d56"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=5.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=9.0>]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 7"
      ],
      "metadata": {
        "id": "cFpPQTeqRSmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "x = tf.constant(np.array([1., 4., 3.]).reshape(1, 3), dtype=tf.float32)\n",
        "W = tf.Variable(tf.random.uniform((3, 2)), dtype=tf.float32)\n",
        "b = tf.Variable(tf.zeros((2,)), dtype=tf.float32)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    f = tf.matmul(x, W) + b\n",
        "\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(f, [W, b])"
      ],
      "metadata": {
        "id": "YQNi24UUPGnB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_of_y_wrt_W_and_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_Jmu-DNSQIw",
        "outputId": "3d026697-e9e6-4105-e2ea-fb3802d149e1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[1., 1.],\n",
              "        [4., 4.],\n",
              "        [3., 3.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 8"
      ],
      "metadata": {
        "id": "WSGb1ax2THSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "x = tf.constant(np.array([1., 4., 3.]).reshape(1, 3), dtype=tf.float32)\n",
        "W = tf.Variable(tf.random.uniform((3, 2)), dtype=tf.float32)\n",
        "b = tf.Variable(tf.zeros((2,)), dtype=tf.float32)\n",
        "\n",
        "# 함수 정의 및 미분\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch([W, b])\n",
        "    f = tf.pow(tf.matmul(x, W) + b, 3)\n",
        "\n",
        "# 미분 수행\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(f, [W, b])"
      ],
      "metadata": {
        "id": "tUg_i_V8SRqB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_of_y_wrt_W_and_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2rMAMRNTUOE",
        "outputId": "6c8f0a62-44bb-4c37-8a89-a245f6894818"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[ 41.4384 ,  32.05867],\n",
              "        [165.7536 , 128.23468],\n",
              "        [124.3152 ,  96.17601]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([41.4384 , 32.05867], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 8"
      ],
      "metadata": {
        "id": "cj3Sujn5UG09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        self.activation = activation\n",
        "\n",
        "        w_shape = (input_size, output_size)\n",
        "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "        self.W = tf.Variable(w_initial_value)\n",
        "\n",
        "        b_shape = (output_size,)\n",
        "        b_initial_value = tf.zeros(b_shape)\n",
        "        self.b = tf.Variable(b_initial_value)\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b]"
      ],
      "metadata": {
        "id": "hHemMNJKTU34"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exD = NaiveDense( 5, 10, activation = tf.nn.relu)\n",
        "exD.weights[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY0FdMdGUJNk",
        "outputId": "d974618b-6aac-4891-be35-d76a851733c0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([5, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdj0PxH6UNAe",
        "outputId": "ef468455-f5d1-48b6-c748-26b9a44ac683"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.NaiveDense at 0x7845305cbd10>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 9"
      ],
      "metadata": {
        "id": "Lbg8MYioV-az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "           x = layer(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "       weights = []\n",
        "       for layer in self.layers:\n",
        "           weights += layer.weights\n",
        "       return weights"
      ],
      "metadata": {
        "id": "5cP00DUJUOT_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
        "])\n",
        "assert len(model.weights) == 4"
      ],
      "metadata": {
        "id": "3ilfFT6IWBkc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtNRb_gdWEpw",
        "outputId": "b5df15b5-6b01-44b3-e4e0-f1a2688b4bc7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.NaiveSequential at 0x784530551190>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ],
      "metadata": {
        "id": "uU5ema-VWFZe"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images_batch)\n",
        "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            labels_batch, predictions)\n",
        "        average_loss = tf.reduce_mean(per_sample_losses)\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss"
      ],
      "metadata": {
        "id": "kHpjV18RXA8h"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    for g, w in zip(gradients, weights):\n",
        "        w.assign_sub(g * learning_rate)"
      ],
      "metadata": {
        "id": "cn5R_ZqeXCod"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    optimizer.apply_gradients(zip(gradients, weights))"
      ],
      "metadata": {
        "id": "3ir93ExkXDtO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "        print(f\"Epoch {epoch_counter}\")\n",
        "        batch_generator = BatchGenerator(images, labels)\n",
        "        for batch_counter in range(batch_generator.num_batches):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch)\n",
        "            if batch_counter % 100 == 0:\n",
        "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
      ],
      "metadata": {
        "id": "bdyqCbAtXFJO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EYqm7wwXGqt",
        "outputId": "dd57e8b1-217a-48f9-fa45-373243611363"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Epoch 0\n",
            "loss at batch 0: 6.41\n",
            "loss at batch 100: 2.23\n",
            "loss at batch 200: 2.20\n",
            "loss at batch 300: 2.08\n",
            "loss at batch 400: 2.19\n",
            "Epoch 1\n",
            "loss at batch 0: 1.87\n",
            "loss at batch 100: 1.86\n",
            "loss at batch 200: 1.82\n",
            "loss at batch 300: 1.69\n",
            "loss at batch 400: 1.79\n",
            "Epoch 2\n",
            "loss at batch 0: 1.55\n",
            "loss at batch 100: 1.56\n",
            "loss at batch 200: 1.49\n",
            "loss at batch 300: 1.41\n",
            "loss at batch 400: 1.46\n",
            "Epoch 3\n",
            "loss at batch 0: 1.29\n",
            "loss at batch 100: 1.33\n",
            "loss at batch 200: 1.23\n",
            "loss at batch 300: 1.19\n",
            "loss at batch 400: 1.24\n",
            "Epoch 4\n",
            "loss at batch 0: 1.10\n",
            "loss at batch 100: 1.15\n",
            "loss at batch 200: 1.04\n",
            "loss at batch 300: 1.03\n",
            "loss at batch 400: 1.08\n",
            "Epoch 5\n",
            "loss at batch 0: 0.96\n",
            "loss at batch 100: 1.01\n",
            "loss at batch 200: 0.90\n",
            "loss at batch 300: 0.92\n",
            "loss at batch 400: 0.96\n",
            "Epoch 6\n",
            "loss at batch 0: 0.85\n",
            "loss at batch 100: 0.90\n",
            "loss at batch 200: 0.80\n",
            "loss at batch 300: 0.83\n",
            "loss at batch 400: 0.88\n",
            "Epoch 7\n",
            "loss at batch 0: 0.78\n",
            "loss at batch 100: 0.82\n",
            "loss at batch 200: 0.73\n",
            "loss at batch 300: 0.76\n",
            "loss at batch 400: 0.81\n",
            "Epoch 8\n",
            "loss at batch 0: 0.71\n",
            "loss at batch 100: 0.75\n",
            "loss at batch 200: 0.67\n",
            "loss at batch 300: 0.71\n",
            "loss at batch 400: 0.76\n",
            "Epoch 9\n",
            "loss at batch 0: 0.67\n",
            "loss at batch 100: 0.70\n",
            "loss at batch 200: 0.62\n",
            "loss at batch 300: 0.66\n",
            "loss at batch 400: 0.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(test_images)\n",
        "predictions = predictions.numpy()\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == test_labels\n",
        "print(f\"accuracy: {matches.mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO4bZoJUXISG",
        "outputId": "d2c637fe-441b-4e09-d2fc-c2671912cd67"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NgCF0h13XY-5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}