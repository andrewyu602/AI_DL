{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOn1AGs5gmzBwrHqeiQ2fiN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewyu602/AI_DL/blob/main/week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CH.3"
      ],
      "metadata": {
        "id": "sHv-l6iFpvwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "pcIsO-WVqAmo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "10E8avffeLT8"
      },
      "outputs": [],
      "source": [
        "#Sample Question1\n",
        "num_samples_per_class = 1000\n",
        "negative_samples = np.random.multivariate_normal(\n",
        "    mean=[0, 3],\n",
        "    cov=[[1, 0.5],[0.5, 1]],\n",
        "    size=num_samples_per_class)\n",
        "positive_samples = np.random.multivariate_normal(\n",
        "    mean=[3, 0],\n",
        "    cov=[[1, 0.5],[0.5, 1]],\n",
        "    size=num_samples_per_class)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)"
      ],
      "metadata": {
        "id": "XpZd0plZqoK2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = np.vstack((np.zeros((num_samples_per_class, 1), dtype=\"float32\"),\n",
        "                     np.ones((num_samples_per_class, 1), dtype=\"float32\")))"
      ],
      "metadata": {
        "id": "2GeRmXqCp0fC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 2\n",
        "output_dim = 1\n",
        "W = tf.Variable(initial_value=tf.random.uniform(shape=(input_dim, output_dim)))\n",
        "b = tf.Variable(initial_value=tf.zeros(shape=(output_dim,)))"
      ],
      "metadata": {
        "id": "Iia40qOfqvpm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(inputs):\n",
        "    return tf.matmul(inputs, W) + b"
      ],
      "metadata": {
        "id": "Sz8zSRviq0Qk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def square_loss(targets, predictions):\n",
        "    per_sample_losses = tf.square(targets - predictions)\n",
        "    return tf.reduce_mean(per_sample_losses)"
      ],
      "metadata": {
        "id": "D-9ZCa2IrCuk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "def training_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs)\n",
        "        loss = square_loss(targets, predictions)\n",
        "    grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n",
        "    W.assign_sub(grad_loss_wrt_W * learning_rate)\n",
        "    b.assign_sub(grad_loss_wrt_b * learning_rate)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "sQcKGn7urD8P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(5):\n",
        "    loss = training_step(inputs, targets)\n",
        "    print(f\"Loss at step {step}: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKJlaTJzrFSB",
        "outputId": "04a0958b-084c-4fa4-9832-004169122e4b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at step 0: 5.0492\n",
            "Loss at step 1: 0.5026\n",
            "Loss at step 2: 0.1827\n",
            "Loss at step 3: 0.1327\n",
            "Loss at step 4: 0.1184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample Question2\n",
        "def model(inputs):\n",
        "    return tf.matmul(inputs, W)"
      ],
      "metadata": {
        "id": "ZKTxNbKMrQzX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def square_loss(targets, predictions):\n",
        "    per_sample_losses = tf.square(targets - predictions)\n",
        "    return tf.reduce_mean(per_sample_losses)"
      ],
      "metadata": {
        "id": "XM6rcLfOrb50"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "def training_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs)\n",
        "        loss = square_loss(targets, predictions)\n",
        "    grad_loss_wrt_W = tape.gradient(loss, W)\n",
        "    W.assign_sub(grad_loss_wrt_W * learning_rate)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "pD-jkXQmrc9L"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(40):\n",
        "    loss = training_step(inputs, targets)\n",
        "    print(f\"Loss at step {step}: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fZ0lO6creUv",
        "outputId": "7bc4665f-b327-4322-adb4-e00a6efc6bc0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at step 0: 0.0945\n",
            "Loss at step 1: 0.0897\n",
            "Loss at step 2: 0.0894\n",
            "Loss at step 3: 0.0894\n",
            "Loss at step 4: 0.0894\n",
            "Loss at step 5: 0.0894\n",
            "Loss at step 6: 0.0894\n",
            "Loss at step 7: 0.0894\n",
            "Loss at step 8: 0.0894\n",
            "Loss at step 9: 0.0894\n",
            "Loss at step 10: 0.0894\n",
            "Loss at step 11: 0.0894\n",
            "Loss at step 12: 0.0894\n",
            "Loss at step 13: 0.0894\n",
            "Loss at step 14: 0.0894\n",
            "Loss at step 15: 0.0894\n",
            "Loss at step 16: 0.0894\n",
            "Loss at step 17: 0.0894\n",
            "Loss at step 18: 0.0894\n",
            "Loss at step 19: 0.0894\n",
            "Loss at step 20: 0.0894\n",
            "Loss at step 21: 0.0894\n",
            "Loss at step 22: 0.0894\n",
            "Loss at step 23: 0.0894\n",
            "Loss at step 24: 0.0894\n",
            "Loss at step 25: 0.0894\n",
            "Loss at step 26: 0.0894\n",
            "Loss at step 27: 0.0894\n",
            "Loss at step 28: 0.0894\n",
            "Loss at step 29: 0.0894\n",
            "Loss at step 30: 0.0894\n",
            "Loss at step 31: 0.0894\n",
            "Loss at step 32: 0.0894\n",
            "Loss at step 33: 0.0894\n",
            "Loss at step 34: 0.0894\n",
            "Loss at step 35: 0.0894\n",
            "Loss at step 36: 0.0894\n",
            "Loss at step 37: 0.0894\n",
            "Loss at step 38: 0.0894\n",
            "Loss at step 39: 0.0894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ch.4"
      ],
      "metadata": {
        "id": "uW18dlzXrvdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample Question1\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "35COeL-_rh1U"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "UH7LdSxUsMyc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
        "    num_words=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAbVyHVMsWmL",
        "outputId": "f278419b-780a-4014-984b-8ce4855b3ad8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] = 1.\n",
        "    return results\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "metadata": {
        "id": "ag-x4FADtGfw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.asarray(train_labels).astype(\"float32\")\n",
        "y_test = np.asarray(test_labels).astype(\"float32\")"
      ],
      "metadata": {
        "id": "c9CeC8DAtdsY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "metadata": {
        "id": "uub4cBPgsNJ_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARvlWPFWsQB7",
        "outputId": "bf1bc3c2-54e3-4a31-918d-79f897a24424"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.6857 - loss: 0.6453 - val_accuracy: 0.8176 - val_loss: 0.5614\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8462 - loss: 0.5318 - val_accuracy: 0.8406 - val_loss: 0.4983\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8687 - loss: 0.4648 - val_accuracy: 0.8543 - val_loss: 0.4530\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8832 - loss: 0.4162 - val_accuracy: 0.8608 - val_loss: 0.4202\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8934 - loss: 0.3787 - val_accuracy: 0.8681 - val_loss: 0.3939\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9021 - loss: 0.3501 - val_accuracy: 0.8744 - val_loss: 0.3735\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9028 - loss: 0.3298 - val_accuracy: 0.8768 - val_loss: 0.3570\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9161 - loss: 0.3037 - val_accuracy: 0.8795 - val_loss: 0.3439\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9205 - loss: 0.2894 - val_accuracy: 0.8821 - val_loss: 0.3332\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9181 - loss: 0.2808 - val_accuracy: 0.8842 - val_loss: 0.3245\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9216 - loss: 0.2685 - val_accuracy: 0.8856 - val_loss: 0.3169\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9301 - loss: 0.2533 - val_accuracy: 0.8868 - val_loss: 0.3111\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9292 - loss: 0.2460 - val_accuracy: 0.8885 - val_loss: 0.3053\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9338 - loss: 0.2340 - val_accuracy: 0.8885 - val_loss: 0.3008\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9377 - loss: 0.2246 - val_accuracy: 0.8892 - val_loss: 0.2967\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9360 - loss: 0.2223 - val_accuracy: 0.8904 - val_loss: 0.2934\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9422 - loss: 0.2101 - val_accuracy: 0.8905 - val_loss: 0.2905\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9411 - loss: 0.2086 - val_accuracy: 0.8906 - val_loss: 0.2880\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9438 - loss: 0.2018 - val_accuracy: 0.8906 - val_loss: 0.2858\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9427 - loss: 0.1981 - val_accuracy: 0.8903 - val_loss: 0.2840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample Question2\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "bTPZ3kqruCna"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "MIb5v2tIurdo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwDwyz-pucrM",
        "outputId": "b8c9ffcf-8231-4869-ef28-6cd570733c99"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.7312 - loss: 0.5799 - val_accuracy: 0.8604 - val_loss: 0.4074\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8892 - loss: 0.3544 - val_accuracy: 0.8798 - val_loss: 0.3315\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9130 - loss: 0.2758 - val_accuracy: 0.8878 - val_loss: 0.3002\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9296 - loss: 0.2269 - val_accuracy: 0.8881 - val_loss: 0.2842\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9358 - loss: 0.2004 - val_accuracy: 0.8790 - val_loss: 0.2976\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9456 - loss: 0.1770 - val_accuracy: 0.8849 - val_loss: 0.2870\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9511 - loss: 0.1589 - val_accuracy: 0.8874 - val_loss: 0.2764\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9543 - loss: 0.1482 - val_accuracy: 0.8876 - val_loss: 0.2787\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9650 - loss: 0.1309 - val_accuracy: 0.8843 - val_loss: 0.2867\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9696 - loss: 0.1152 - val_accuracy: 0.8867 - val_loss: 0.2897\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9676 - loss: 0.1138 - val_accuracy: 0.8840 - val_loss: 0.2936\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9752 - loss: 0.0990 - val_accuracy: 0.8856 - val_loss: 0.3032\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9779 - loss: 0.0930 - val_accuracy: 0.8678 - val_loss: 0.3509\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9790 - loss: 0.0867 - val_accuracy: 0.8818 - val_loss: 0.3170\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9826 - loss: 0.0783 - val_accuracy: 0.8737 - val_loss: 0.3368\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9839 - loss: 0.0737 - val_accuracy: 0.8780 - val_loss: 0.3350\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9868 - loss: 0.0693 - val_accuracy: 0.8752 - val_loss: 0.3472\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9882 - loss: 0.0627 - val_accuracy: 0.8786 - val_loss: 0.3578\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9901 - loss: 0.0577 - val_accuracy: 0.8768 - val_loss: 0.3586\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9901 - loss: 0.0552 - val_accuracy: 0.8752 - val_loss: 0.3692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample Question3.\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "IkQyj-4Xupc5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"mse\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Tg6KtTPnu8P8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrNenz0avLn_",
        "outputId": "cdc21821-869a-47c4-b409-3333804ad5ad"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 83ms/step - accuracy: 0.6875 - loss: 0.2085 - val_accuracy: 0.8655 - val_loss: 0.1273\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8875 - loss: 0.1103 - val_accuracy: 0.8702 - val_loss: 0.1086\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9166 - loss: 0.0832 - val_accuracy: 0.8855 - val_loss: 0.0942\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9279 - loss: 0.0694 - val_accuracy: 0.8801 - val_loss: 0.0924\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9368 - loss: 0.0634 - val_accuracy: 0.8802 - val_loss: 0.0906\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9443 - loss: 0.0557 - val_accuracy: 0.8874 - val_loss: 0.0849\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9524 - loss: 0.0496 - val_accuracy: 0.8839 - val_loss: 0.0861\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9526 - loss: 0.0470 - val_accuracy: 0.8867 - val_loss: 0.0839\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9591 - loss: 0.0443 - val_accuracy: 0.8838 - val_loss: 0.0843\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9658 - loss: 0.0392 - val_accuracy: 0.8831 - val_loss: 0.0847\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9666 - loss: 0.0381 - val_accuracy: 0.8820 - val_loss: 0.0851\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9696 - loss: 0.0346 - val_accuracy: 0.8773 - val_loss: 0.0879\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9709 - loss: 0.0331 - val_accuracy: 0.8827 - val_loss: 0.0851\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9736 - loss: 0.0312 - val_accuracy: 0.8812 - val_loss: 0.0858\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9757 - loss: 0.0290 - val_accuracy: 0.8808 - val_loss: 0.0862\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9770 - loss: 0.0287 - val_accuracy: 0.8809 - val_loss: 0.0867\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9798 - loss: 0.0267 - val_accuracy: 0.8797 - val_loss: 0.0874\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9829 - loss: 0.0239 - val_accuracy: 0.8737 - val_loss: 0.0914\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9823 - loss: 0.0230 - val_accuracy: 0.8692 - val_loss: 0.0967\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9827 - loss: 0.0226 - val_accuracy: 0.8788 - val_loss: 0.0891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample Question4.\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"tanh\"),\n",
        "    layers.Dense(16, activation=\"tanh\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "u1sWUxtNvNRz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"mse\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "xv0CRnBfwH9F"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlOcNj2KwLDs",
        "outputId": "7b720523-6000-4135-bd87-e3b88bf40b1e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.6939 - loss: 0.2049 - val_accuracy: 0.8471 - val_loss: 0.1288\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8926 - loss: 0.1041 - val_accuracy: 0.8755 - val_loss: 0.0980\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9154 - loss: 0.0746 - val_accuracy: 0.8875 - val_loss: 0.0862\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9360 - loss: 0.0569 - val_accuracy: 0.8852 - val_loss: 0.0849\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9449 - loss: 0.0481 - val_accuracy: 0.8823 - val_loss: 0.0880\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9574 - loss: 0.0392 - val_accuracy: 0.8851 - val_loss: 0.0842\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9654 - loss: 0.0325 - val_accuracy: 0.8745 - val_loss: 0.0924\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9695 - loss: 0.0284 - val_accuracy: 0.8813 - val_loss: 0.0909\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9738 - loss: 0.0250 - val_accuracy: 0.8670 - val_loss: 0.1034\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9776 - loss: 0.0219 - val_accuracy: 0.8607 - val_loss: 0.1097\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9805 - loss: 0.0199 - val_accuracy: 0.8772 - val_loss: 0.0968\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9864 - loss: 0.0145 - val_accuracy: 0.8726 - val_loss: 0.1008\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9845 - loss: 0.0154 - val_accuracy: 0.8755 - val_loss: 0.1000\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9876 - loss: 0.0126 - val_accuracy: 0.8761 - val_loss: 0.1011\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9894 - loss: 0.0114 - val_accuracy: 0.8753 - val_loss: 0.1029\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9915 - loss: 0.0097 - val_accuracy: 0.8713 - val_loss: 0.1093\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9803 - loss: 0.0171 - val_accuracy: 0.8752 - val_loss: 0.1054\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9877 - loss: 0.0118 - val_accuracy: 0.8716 - val_loss: 0.1079\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9916 - loss: 0.0086 - val_accuracy: 0.8709 - val_loss: 0.1081\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9917 - loss: 0.0089 - val_accuracy: 0.8692 - val_loss: 0.1093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mLE01W8rwMUs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}